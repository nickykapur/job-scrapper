# ğŸ§¹ Database Cleanup Instructions

## Current State:
- ğŸ‡¬ğŸ‡§ **United Kingdom**: 1000+ jobs (need to remove ~700)
- ğŸ‡ªğŸ‡¸ **Spain**: 900 jobs (need to remove ~600)
- ğŸ‡©ğŸ‡ª **Germany**: 310 jobs (need to remove ~10)
- ğŸ‡®ğŸ‡ª **Ireland**: ? jobs

**Total jobs to delete**: ~1,310+ old jobs

---

## ğŸš€ Quick Fix (Run These Commands):

### Option 1: Automated Script (Recommended)

```bash
cd /mnt/c/Users/nicky/OneDrive/Escritorio/Projects/python-job/job-scrapper

# Set your Railway database URL
export DATABASE_URL='your_railway_postgres_connection_string'

# Run the migration script
bash run_database_migrations.sh
```

This will:
1. âœ… Add `easy_apply` column
2. âœ… Delete old jobs (keep 300 newest per country)
3. âœ… Show verification stats

---

### Option 2: Manual Commands

```bash
# Set your Railway database URL
export DATABASE_URL='your_railway_postgres_connection_string'

# Step 1: Add easy_apply column
psql "$DATABASE_URL" -f add_easy_apply_column.sql

# Step 2: Clean up to 300 jobs per country
psql "$DATABASE_URL" -f cleanup_database_300_limit.sql

# Step 3: Verify
psql "$DATABASE_URL" -c "
  SELECT country, COUNT(*) as jobs
  FROM jobs
  GROUP BY country
  ORDER BY jobs DESC;
"
```

---

## ğŸ“Š What Will Happen:

### Before Cleanup:
```
United Kingdom: 1000+ jobs
Spain:          900 jobs
Germany:        310 jobs
Ireland:        ? jobs
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:          2200+ jobs âŒ
```

### After Cleanup:
```
United Kingdom: 300 jobs âœ…
Spain:          300 jobs âœ…
Germany:        300 jobs âœ…
Ireland:        300 jobs âœ…
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:          ~1200 jobs âœ…
```

**Jobs deleted**: ~1,000+ old entries

---

## ğŸ” How It Chooses Which Jobs to Keep:

The script keeps the **300 most recent jobs** per country based on `scraped_at` timestamp:

```sql
-- Example for UK
SELECT id, title, scraped_at
FROM jobs
WHERE country = 'United Kingdom'
ORDER BY scraped_at DESC  -- Most recent first
LIMIT 300;                -- Keep these
-- Delete the rest
```

So you'll keep:
- âœ… The freshest job listings
- âœ… Most recently scraped jobs
- âœ… Jobs with latest timestamps

You'll delete:
- âŒ Old job listings (no longer relevant)
- âŒ Jobs scraped weeks ago
- âŒ Stale opportunities

---

## âš ï¸ Safety Features:

The cleanup script:
1. **Uses transaction (BEGIN/COMMIT)** - Can rollback if something goes wrong
2. **Shows BEFORE counts** - See what you have before deletion
3. **Shows AFTER counts** - Verify 300 limit was applied
4. **Shows date ranges** - See oldest and newest job kept
5. **Asks for confirmation** - Won't delete without your approval

---

## ğŸ¯ Why This Is Important:

### Database Performance:
- **Before**: 2200+ rows â†’ Slow queries
- **After**: 1200 rows â†’ Fast queries âš¡

### UI Performance:
- **Before**: Loading 2200+ jobs â†’ UI lag
- **After**: Loading 1200 jobs â†’ Smooth UI ğŸš€

### Data Freshness:
- **Before**: Jobs from weeks ago (already filled)
- **After**: Only recent jobs (still available) ğŸ“…

### Cost:
- **Before**: Larger database â†’ Higher Railway costs
- **After**: Optimized size â†’ Lower costs ğŸ’°

---

## ğŸ”§ Troubleshooting:

### "ERROR: column 'easy_apply' already exists"
**Solution**: This is OK! It means the column was already added. Continue to cleanup.

### "ERROR: column 'scraped_at' does not exist"
**Solution**: Your jobs don't have timestamps. Run:
```sql
ALTER TABLE jobs ADD COLUMN scraped_at TIMESTAMP DEFAULT NOW();
UPDATE jobs SET scraped_at = NOW() WHERE scraped_at IS NULL;
```

### "ERROR: relation 'jobs' does not exist"
**Solution**: Wrong database or table name. Check your DATABASE_URL.

---

## âœ… Verification After Cleanup:

```bash
# Check job counts
psql "$DATABASE_URL" -c "
  SELECT
    country,
    COUNT(*) as total_jobs,
    MAX(scraped_at) as newest,
    MIN(scraped_at) as oldest
  FROM jobs
  GROUP BY country;
"

# Should show:
# United Kingdom | 300 | 2025-01-07 | 2025-01-05
# Spain          | 300 | 2025-01-07 | 2025-01-05
# Germany        | 300 | 2025-01-07 | 2025-01-06
# Ireland        | 300 | 2025-01-07 | 2025-01-06
```

All countries should have â‰¤ 300 jobs! âœ…

---

## ğŸ“ After Cleanup:

1. **Rebuild Frontend**:
```bash
cd job-manager-ui
npm run build
```

2. **Trigger GitHub Action** (or wait for scheduled run):
- Go to: GitHub â†’ Actions â†’ Daily Multi-Country Job Scraper
- Click: "Run workflow"

3. **Check Logs** for:
```
âœ‚ï¸ Applying 300 jobs per country limit...
   âœ… Ireland: 120 jobs (no trim needed)
   âœ… Spain: 295 jobs (no trim needed)
   âœ… Germany: 180 jobs (no trim needed)
   âœ… United Kingdom: 285 jobs (no trim needed)
```

4. **Check UI** for:
- âš¡ Green "Easy Apply" badges
- Clean country tabs
- Faster load times

---

## ğŸ†˜ Need Help?

If something goes wrong, you can restore from Railway backup:
1. Go to Railway Dashboard
2. Select your database
3. Click "Backups" tab
4. Restore to before cleanup

---

## ğŸ‰ Expected Result:

After running cleanup:
- âœ… Database: 1,200 jobs (300 per country)
- âœ… All jobs have `easy_apply` column
- âœ… UI shows Easy Apply badges
- âœ… Countries capped at 300 jobs
- âœ… Faster performance
- âœ… Lower costs

**Total deletion**: ~1,000 old jobs (47% reduction) ğŸ“‰

Ready to clean? Run:
```bash
bash run_database_migrations.sh
```
